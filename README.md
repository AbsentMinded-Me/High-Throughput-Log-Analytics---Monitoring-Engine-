# ğŸš€ Python-Based High Throughput Log Analytics Monitoring Engine

A **real-time log analytics and anomaly detection system** built using **Python, Dask, and Streamlit**.
This project simulates real-time log generation, processes logs in parallel, detects anomalies using statistical techniques, and visualizes them through an interactive dashboard.

---

## âœ¨ Key Features

* Real-time log generation
* Parallel log ingestion & processing using **Dask**
* Z-scoreâ€“based anomaly detection
* Interactive **Streamlit + Plotly** dashboard
* Modular & scalable architecture
* MIT Licensed

---

## ğŸ—‚ï¸ Project Structure

```
.
â”œâ”€â”€ anomaly/
â”‚   â””â”€â”€ detector.py
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ dask_config.py
â”‚   â””â”€â”€ email_config.py
â”‚
â”œâ”€â”€ dashboard/
â”‚   â””â”€â”€ app.py
â”‚
â”œâ”€â”€ ingestion/
â”‚   â”œâ”€â”€ loader.py
â”‚   â””â”€â”€ parser.py
â”‚
â”œâ”€â”€ processing/
â”‚   â””â”€â”€ pipeline.py
â”‚
â”œâ”€â”€ log_generator/
â”‚   â”œâ”€â”€ realtime_log_producer.py
â”‚   â””â”€â”€ realtime_logs.csv
â”‚
â”œâ”€â”€ schema/
â”‚   â””â”€â”€ schema.py
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sample_log.log
â”‚
â”œâ”€â”€ main.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md
â””â”€â”€ logvenv/
```

---

## ğŸ“„ File Overview

### ğŸ”¹ `log_generator/realtime_log_producer.py`

Simulates **real-time log generation** and continuously writes logs into `realtime_logs.csv`.

* Random log levels: `INFO`, `WARN`, `ERROR`
* Random services: `auth`, `payment`, `orders`, `search`
* Mimics real production log streams

---

### ğŸ”¹ `main.py`

Acts as the **core controller** of the system:

* Initializes Dask cluster
* Runs log ingestion & processing pipeline
* Detects anomalies
* (Optional) Sends email alerts

---

### ğŸ”¹ `dashboard/app.py`

A **Streamlit dashboard** that:

* Reads processed logs
* Detects anomalies
* Visualizes anomaly scores using Plotly
* Allows threshold-based filtering via slider

> Runs independently from `main.py`

---

### ğŸ”¹ `processing/pipeline.py`

Builds the log processing pipeline:

* Loads logs using Dask Bag
* Parses logs
* Converts them into a Dask DataFrame
* Handles timestamp conversion

---

### ğŸ”¹ `ingestion/loader.py`

Loads log files efficiently using **Dask Bag** for parallel processing.

---

### ğŸ”¹ `ingestion/parser.py`

Parses raw log lines using **regular expressions** and extracts:

* timestamp
* level
* service
* message

---

### ğŸ”¹ `anomaly/detector.py`

Detects anomalies by:

* Filtering `ERROR` logs
* Aggregating errors per minute
* Computing **Z-scores**
* Flagging statistically significant spikes

---

### ğŸ”¹ `config/dask_config.py`

Configures and launches a **local Dask cluster** with:

* Multiple workers
* Threaded execution
* Dask dashboard enabled

---

### ğŸ”¹ `schema/schema.py`

Defines the expected schema of logs to ensure consistency during processing.

---

### ğŸ”¹ `data/sample_log.log`

Sample log file for testing and validation.

---

## âš™ï¸ Installation

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/your-username/your-repo-name.git
cd your-repo-name
```

---

### 2ï¸âƒ£ Activate Virtual Environment

```bash
logvenv\Scripts\activate   # Windows
# or
source logvenv/bin/activate  # macOS/Linux
```

---

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

If needed manually:

```bash
pip install dask[distributed] streamlit plotly pandas
```

---

## â–¶ï¸ How to Run the Project

### ğŸŸ¢ Step 1: Start Real-Time Log Producer

```bash
python log_generator/realtime_log_producer.py
```

This will continuously generate logs in real time.

---

### ğŸŸ¢ Step 2: Run Main Processing Engine

```bash
python main.py
```

This will:

* Start Dask
* Process logs
* Detect anomalies

---

### ğŸŸ¢ Step 3: Launch Streamlit Dashboard

```bash
streamlit run dashboard/app.py
```

Open in browser:

```
http://localhost:8501
```

---

## ğŸ“Š Dashboard Capabilities

* View detected anomalies
* Interactive anomaly score line chart
* Threshold-based anomaly filtering
* Tabular display of anomalous entries

---

## ğŸ” Security Note

For production use:

* Move email credentials to **environment variables**
* Avoid hardcoding sensitive information

---

## ğŸ“œ License

This project is licensed under the **MIT License**.

```
MIT License

Copyright (c) 2026 Tanisha Gupta
```

See the full license in the `LICENSE` file.

---

## ğŸ¤ Contributing

Contributions are welcome!
Feel free to open issues or submit pull requests.

---

## â­ Acknowledgements

* **Dask** â€“ Parallel computing
* **Streamlit** â€“ Interactive dashboards
* **Plotly** â€“ Data visualization


